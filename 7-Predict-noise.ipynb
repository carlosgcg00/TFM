{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a14c00-f051-4b73-aeaa-c774ac4651bc",
   "metadata": {},
   "source": [
    "# **Instalación de librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca71d4-8de8-4190-b035-6b9f90c397d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "!pip install pytorch-lightning pycocotools\n",
    "!pip install torchmetrics\n",
    "!pip install torchvision\n",
    "!pip install albumentations\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75c29b-1353-4abc-8325-75167eaca95b",
   "metadata": {},
   "source": [
    "# **Predicciones con ruido**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946a90c-9496-42a2-80b0-61b664ab6ee0",
   "metadata": {},
   "source": [
    "Tras realizar el análisis de las métricas de ruido, se pueden realizar unas predicciones del modelo en el que se este se vea afectado por el ruido. Se han introducido diferentes niveles de ruido para los diferentes casos, durante las predicciones, estas predicciones son almacenadas en la subcarpeta correspondiente al modelo en ***test_noise***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea5afc2-185a-4209-b64b-1ea8bc23f44f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "Model loaded: tinyissimoYOLO/NAdam_None_Airbus_256_BATCH_32_LR_0.0005/model_opt/6-TIC_5_sims_max_steps_100_slices_5_interval_4_10_degredation_0/sim_4/YOLO_opt.pth.tar\n",
      "[1/3] - Processing: test_video4_Barajas.mp4\n",
      "Output video path: /home/jovyan/Carlos_Gonzalez/YOLO/tinyissimoYOLO/NAdam_None_Airbus_256_BATCH_32_LR_0.0005/model_opt/6-TIC_5_sims_max_steps_100_slices_5_interval_4_10_degredation_0/sim_4/test_noise/test_video4_Barajas_predicted.mp4\n",
      "Average inference time per frame: 0.140988 seconds\n",
      "[2/3] - Processing: test_video5-El Prat.mp4\n",
      "Output video path: /home/jovyan/Carlos_Gonzalez/YOLO/tinyissimoYOLO/NAdam_None_Airbus_256_BATCH_32_LR_0.0005/model_opt/6-TIC_5_sims_max_steps_100_slices_5_interval_4_10_degredation_0/sim_4/test_noise/test_video5-El Prat_predicted.mp4\n",
      "Average inference time per frame: 0.148139 seconds\n",
      "[3/3] - Processing: test_video6_CuatroVientos.mp4\n",
      "Output video path: /home/jovyan/Carlos_Gonzalez/YOLO/tinyissimoYOLO/NAdam_None_Airbus_256_BATCH_32_LR_0.0005/model_opt/6-TIC_5_sims_max_steps_100_slices_5_interval_4_10_degredation_0/sim_4/test_noise/test_video6_CuatroVientos_predicted.mp4\n",
      "Average inference time per frame: 0.142677 seconds\n"
     ]
    }
   ],
   "source": [
    "from predict_noise import process_media\n",
    "import os\n",
    "folder_test = 'test'\n",
    "files_to_test = os.listdir(folder_test)\n",
    "files_to_test = ['test_video4_Barajas.mp4', 'test_video5-El Prat.mp4', 'test_video6_CuatroVientos.mp4']\n",
    "case1 = False\n",
    "case2 = False\n",
    "\n",
    "percentage_layers_case_1  = 0.5 if case1 else 0\n",
    "percentage_layers_case_2 = 0.5 if case2 else 0\n",
    "# Con este parámetro seleccionamos la zona en la que queremos afectar a las activacionies o pesos\n",
    "# es decir, slices = [slice_i, n_slices], con esto dividimos todas las capas en n_slices y afectamos a las capas que esten en slice_i\n",
    "'''\n",
    "|slice 0 | slice 1 | slice 2 | slice 3 | slice 4 | \n",
    "'''\n",
    "interval_1 = (-8, 2)\n",
    "interval_2 = (-8, 2)\n",
    "slices_case1 = [0,1] \n",
    "slices_case2 = [0,1]\n",
    "percentage_tensors_1 = 0.05\n",
    "percentage_tensors_2 = 0.002\n",
    "\n",
    "\n",
    "folder_model = '6-TIC_5_sims_max_steps_100_slices_5_interval_4_10_degredation_0/sim_4'\n",
    "model_name = 'YOLO_opt.pth.tar'\n",
    "process_media(folder_test, files_to_test, case1=case1, percentage_layers_case_1=percentage_layers_case_1, slices_case1 = slices_case1, interval_1 = interval_1, percentage_tensors_1= percentage_tensors_1,\n",
    "           case2=case2, percentage_layers_case_2=percentage_layers_case_2, slices_case2 = slices_case2, interval_2 = interval_2, percentage_tensors_2= percentage_tensors_2,\n",
    "                folder_model=folder_model, model_name=model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
