{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1386e94a-30df-4923-9c6b-5ddfc3a746a0",
   "metadata": {},
   "source": [
    "# **Libraries installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536f854-29b3-4fd4-8531-6017698ee2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "!pip install pytorch-lightning pycocotools\n",
    "!pip install torchmetrics\n",
    "!pip install torchvision\n",
    "!pip install albumentations\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36fa8aa-62ed-4298-8e62-c73fd2c62839",
   "metadata": {},
   "source": [
    "In this section we are going to use two type of predictions.\n",
    "\n",
    "The first one is by the use of ***test_tiles.py*** in which the aim of this is to predict by using different kind of tiles. We are going to predict large images from left to right and top to buttom with tiles of a specific size and with an overlap between them, to this end it is going to be used the test_loader.\n",
    "\n",
    "The second one is by the use of ***precict.py*** which is able to do the same and also to make predictions over videos, so in this case we are going to send the root to the specific folder of the images and videos.\n",
    "\n",
    "\n",
    "To use both of them we need to keep the same configuration on ***config.py*** as in ***train.py***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d74f27-cbab-482e-a0a4-8e79083dcfe8",
   "metadata": {},
   "source": [
    "# **Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f10039-46d6-4f5e-8d58-aeb1e4008bb6",
   "metadata": {},
   "source": [
    "By running the ***test_tiles.py*** code you get the metrics to calculate the predictions on the test images, which are 2560x2560 pixel images, you can play with the size and overlapping of the tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb404f3-4dea-4988-b531-0942ee1daff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from predict.test_tiles import test_prediction\n",
    "# test_prediction(tile_size = 256, overlap = 0.2, threshold=0.4, iou_threshold=0.4)\n",
    "# test_prediction(tile_size = 256, overlap = 0.2, threshold=0.4, iou_threshold=0.4)\n",
    "test_prediction(tile_size = 256, overlap = 0.1, threshold=0.4, iou_threshold=0.3)\n",
    "# test_prediction(tile_size = 256, overlap = 0.0, threshold=0.4, iou_threshold=0.4)\n",
    "# test_prediction(tile_size = 350, overlap = 0.2, threshold=0.4, iou_threshold=0.4)\n",
    "# test_prediction(tile_size = 512, overlap = 0.2, threshold=0.4, iou_threshold=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb757a7-32cd-48b0-bd4c-1aeff1fd2d81",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8d96c-a791-4896-8c0f-af57611180d2",
   "metadata": {},
   "source": [
    "To make the predictions, we can execute the file ***inference\n",
    ".py***, in which the model that is loaded with the parameters established in ***config.py*** has to be in tune, as it will search for the corresponding folder, but we will have to indicate which model we want, that is, the one that is within the models saved in the ***models*** folder.\n",
    "\n",
    "The preconditions are made on the images and videos that are inside the ***test*** folder and the result of the prediction will be found inside the folder that refers to the model that we are running.\n",
    "\n",
    "The test tests that have been carried out with:\n",
    "* Test images from the **Airbus Aircraft** dataset.\n",
    "* Video on the **Airbus Aircraft** tesst images, zoomed in and out.\n",
    "* Video of **Barajas airport** and **Barcelona airport**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6d6a1-9876-48bf-8a46-da8bf227bd49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python predict/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59716121-ae47-4b18-ad67-affa655eb5fd",
   "metadata": {},
   "source": [
    "We have several situations, in which we can make inference, we have images and videos, the images chosen are those that we have in the **test** folder of **Airbus**, it has been established that regardless of the model, if the image is smaller than or equal to 256x256 pixels, a resize is made, and then it is processed by the model. But we have a problem of detection in satellite images in which the images are 2560x2560 pixels, so we have to use a technique called *tiles*. \n",
    "\n",
    "This *tiles* technique aims to subdivide the image into squares, in our case of 256 pixels, but we use a technique of overlapping or *overlapping* of the *tiles* to successfully traverse the image. That is, the previous 256x256 pixels square and the new one overlap by a certain percentage, in our case, 20%. This supposes to obtain many Boundary Boxes, for that reason, subsequently to this it is necessary to use the technique of Non Max Suppression that allows the elimination of Boundary Boxes that overlap a certain percentage, this is specified with the parameter *Intersection Over Union*, **IOU**, in addition there is another parameter, ***threshold** that is used to eliminate the Boundary Boxes that has been evaluated by the model with low level of confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd617e-3fab-4a3d-b4b0-d6c8afcd6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict.inference import process_media\n",
    "import os\n",
    "folder_test = os.path.join(os.getcwd(), 'Datasets/test')\n",
    "# files_to_test = ['Aeropuerto.mp4', 'large_image.jpg', 'img1.jpg', 'Barajas.jpg']\n",
    "files_to_test = ['babb0ef2-ef2d-4cab-b3e2-230ae2418cdc.jpg']\n",
    "# files_to_test = os.listdir(folder_test)\n",
    "process_media(folder_test, files_to_test, generate_video_tiles = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
