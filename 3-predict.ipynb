{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1386e94a-30df-4923-9c6b-5ddfc3a746a0",
   "metadata": {},
   "source": [
    "# **Instalación de las librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9536f854-29b3-4fd4-8531-6017698ee2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.2.5-py3-none-any.whl (802 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pycocotools\n",
      "  Downloading pycocotools-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (463 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.7/463.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning) (2.1.2)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>=2022.5.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning) (2023.6.0)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
      "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.11/site-packages (from pytorch-lightning) (4.7.1)\n",
      "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from pycocotools) (3.7.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (68.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->pytorch-lightning) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch-lightning) (12.3.101)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
      "Installing collected packages: lightning-utilities, pycocotools, torchmetrics, pytorch-lightning\n",
      "Successfully installed lightning-utilities-0.11.2 pycocotools-2.0.7 pytorch-lightning-2.2.5 torchmetrics-1.4.0.post0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.11/site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (1.23.5)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (2.1.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from torchmetrics) (0.11.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.7.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchvision\n",
      "  Downloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision) (1.23.5)\n",
      "Collecting torch==2.3.1 (from torchvision)\n",
      "  Downloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.13.1)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.3.1->torchvision)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->torchvision)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
      "Collecting triton==2.3.1 (from torch==2.3.1->torchvision)\n",
      "  Downloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->torchvision) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
      "Installing collected packages: typing-extensions, triton, nvidia-nccl-cu12, torch, torchvision\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.2\n",
      "    Uninstalling torch-2.1.2:\n",
      "      Successfully uninstalled torch-2.1.2\n",
      "Successfully installed nvidia-nccl-cu12-2.20.5 torch-2.3.1 torchvision-0.18.1 triton-2.3.1 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting albumentations\n",
      "  Downloading albumentations-1.4.8-py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.24.4 (from albumentations)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from albumentations) (1.11.1)\n",
      "Collecting scikit-image>=0.21.0 (from albumentations)\n",
      "  Downloading scikit_image-0.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/conda/lib/python3.11/site-packages (from albumentations) (4.12.2)\n",
      "Collecting scikit-learn>=1.3.2 (from albumentations)\n",
      "  Downloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic>=2.7.0 (from albumentations)\n",
      "  Downloading pydantic-2.7.3-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting albucore>=0.0.4 (from albumentations)\n",
      "  Downloading albucore-0.0.9-py3-none-any.whl (7.9 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.10.0.82-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.11/site-packages (from albucore>=0.0.4->albumentations) (2.0.1)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.7.0->albumentations)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic>=2.7.0->albumentations)\n",
      "  Downloading pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (3.1)\n",
      "Requirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (10.0.0)\n",
      "Collecting imageio>=2.33 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (23.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.3.2->albumentations) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.3.2->albumentations) (3.1.0)\n",
      "Installing collected packages: pydantic-core, numpy, lazy-loader, annotated-types, pydantic, opencv-python-headless, imageio, scikit-learn, scikit-image, albucore, albumentations\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "  Attempting uninstall: lazy-loader\n",
      "    Found existing installation: lazy_loader 0.2\n",
      "    Uninstalling lazy_loader-0.2:\n",
      "      Successfully uninstalled lazy_loader-0.2\n",
      "  Attempting uninstall: imageio\n",
      "    Found existing installation: imageio 2.31.1\n",
      "    Uninstalling imageio-2.31.1:\n",
      "      Successfully uninstalled imageio-2.31.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.20.0\n",
      "    Uninstalling scikit-image-0.20.0:\n",
      "      Successfully uninstalled scikit-image-0.20.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed albucore-0.0.9 albumentations-1.4.8 annotated-types-0.7.0 imageio-2.34.1 lazy-loader-0.4 numpy-1.26.4 opencv-python-headless-4.10.0.82 pydantic-2.7.3 pydantic-core-2.18.4 scikit-image-0.23.2 scikit-learn-1.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.82-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.82\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "!pip install pytorch-lightning pycocotools\n",
    "!pip install torchmetrics\n",
    "!pip install torchvision\n",
    "!pip install albumentations\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d74f27-cbab-482e-a0a4-8e79083dcfe8",
   "metadata": {},
   "source": [
    "# **Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f10039-46d6-4f5e-8d58-aeb1e4008bb6",
   "metadata": {},
   "source": [
    "Ejecutando el códifo de ***test_best_model.py*** se sacan las métricas de calcular las predicciones sobre las imagenes de test, que son imagenes 2560x2560 píxeles, se puede jugar con el tamaño y el solapamiento de los tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e36b0b-1e89-4c54-9092-6a43541a5916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "Load: /home/jovyan/Carlos_Gonzalez/YOLO/tinyissimoYOLO/NAdam_None_Airbus_256_BATCH_32_LR_0.0005/model/48_YOLO_best.pth.tar\n",
      "100%|███████████████████████████████████████████| 10/10 [00:16<00:00,  1.66s/it]\n",
      "Inference large image, Time: 1.598618984222412 seconds, FPS: 0.6255399253164833\n",
      "Average inference time per tile: 0.001862 seconds\n",
      "Tile size: 256, Overlap: 0.2\n",
      "mAP50: 0.5988656282424927, mAP75: 0.05853266641497612, mAP90: 9.678561036707833e-05\n"
     ]
    }
   ],
   "source": [
    "!python test_best_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb404f3-4dea-4988-b531-0942ee1daff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "Load: /home/jovyan/Carlos_Gonzalez/YOLO/tinyissimoYOLO/Adam_None_Airbus_256_2_BATCH_32_LR_0.0005/model/43_YOLO_best.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference large image, Time: 1.02 seconds, FPS: 0.98\n",
      "Average inference time per tile: 0.001917 mseconds, Image large: 0.32, Tiles: 169\n",
      "Tile size: 256, Overlap: 0.2\n",
      "mAP50: 0.6167907118797302, mAP75: 0.05681731551885605, mAP90: 3.831250796793029e-05\n",
      "=> Loading checkpoint\n",
      "Load: /home/jovyan/Carlos_Gonzalez/YOLO/tinyissimoYOLO/Adam_None_Airbus_256_2_BATCH_32_LR_0.0005/model/43_YOLO_best.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference large image, Time: 1.32 seconds, FPS: 0.76\n",
      "Average inference time per tile: 0.001924 mseconds, Image large: 0.33, Tiles: 169\n",
      "Tile size: 256, Overlap: 0.2\n",
      "mAP50: 0.653609037399292, mAP75: 0.05792282149195671, mAP90: 3.589508924051188e-05\n",
      "=> Loading checkpoint\n",
      "Load: /home/jovyan/Carlos_Gonzalez/YOLO/tinyissimoYOLO/Adam_None_Airbus_256_2_BATCH_32_LR_0.0005/model/43_YOLO_best.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference large image, Time: 0.92 seconds, FPS: 1.08\n",
      "Average inference time per tile: 0.001948 mseconds, Image large: 0.28, Tiles: 144\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m test_prediction(tile_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m, overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, iou_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_prediction(tile_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m, overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, iou_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtest_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m test_prediction(tile_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m, overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, iou_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# test_prediction(tile_size = 256, overlap = 0.0, threshold=0.4, iou_threshold=0.2)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# test_prediction(tile_size = 350, overlap = 0.2, threshold=0.4, iou_threshold=0.2)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# test_prediction(tile_size = 512, overlap = 0.2, threshold=0.4, iou_threshold=0.2)\u001b[39;00m\n",
      "File \u001b[0;32m~/Carlos_Gonzalez/YOLO/test_best_model.py:176\u001b[0m, in \u001b[0;36mtest_prediction\u001b[0;34m(tile_size, overlap, threshold, iou_threshold)\u001b[0m\n\u001b[1;32m    173\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    175\u001b[0m pred_boxes, target_boxes \u001b[38;5;241m=\u001b[39m get_bboxes_test(model, test_loader, tile_size, overlap, threshold, iou_threshold)\n\u001b[0;32m--> 176\u001b[0m test_mAP50, test_mAP75, test_mAP90 \u001b[38;5;241m=\u001b[39m \u001b[43mmean_average_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_boxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_boxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_thresholds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmidpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_CLASSES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTile size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtile_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Overlap: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverlap\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmAP50: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_mAP50\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mAP75: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_mAP75\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mAP90: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_mAP90\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Carlos_Gonzalez/YOLO/utils.py:170\u001b[0m, in \u001b[0;36mmean_average_precision\u001b[0;34m(pred_boxes, true_boxes, iou_thresholds, box_format, num_classes, best_mAP, epoch, mode)\u001b[0m\n\u001b[1;32m    167\u001b[0m best_iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gt \u001b[38;5;129;01min\u001b[39;00m ground_truth_img:\n\u001b[0;32m--> 170\u001b[0m     iou \u001b[38;5;241m=\u001b[39m \u001b[43mintersection_over_union\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbox_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iou \u001b[38;5;241m>\u001b[39m best_iou:\n\u001b[1;32m    173\u001b[0m         best_iou \u001b[38;5;241m=\u001b[39m iou\n",
      "File \u001b[0;32m~/Carlos_Gonzalez/YOLO/utils.py:73\u001b[0m, in \u001b[0;36mintersection_over_union\u001b[0;34m(boxes_preds, boxes_labels, box_format)\u001b[0m\n\u001b[1;32m     70\u001b[0m     box2_x2 \u001b[38;5;241m=\u001b[39m boxes_labels[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     71\u001b[0m     box2_y2 \u001b[38;5;241m=\u001b[39m boxes_labels[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m---> 73\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox1_x1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox2_x1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m y1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(box1_y1, box2_y1)\n\u001b[1;32m     75\u001b[0m x2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(box1_x2, box2_x2)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from test_best_model import test_prediction\n",
    "test_prediction(tile_size = 256, overlap = 0.2, threshold=0.4, iou_threshold=0.2)\n",
    "test_prediction(tile_size = 256, overlap = 0.2, threshold=0.4, iou_threshold=0.4)\n",
    "test_prediction(tile_size = 256, overlap = 0.1, threshold=0.4, iou_threshold=0.2)\n",
    "test_prediction(tile_size = 128, overlap = 0.1, threshold=0.4, iou_threshold=0.2)\n",
    "# test_prediction(tile_size = 256, overlap = 0.0, threshold=0.4, iou_threshold=0.2)\n",
    "# test_prediction(tile_size = 350, overlap = 0.2, threshold=0.4, iou_threshold=0.2)\n",
    "# test_prediction(tile_size = 512, overlap = 0.2, threshold=0.4, iou_threshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb757a7-32cd-48b0-bd4c-1aeff1fd2d81",
   "metadata": {},
   "source": [
    "# **Predicciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8d96c-a791-4896-8c0f-af57611180d2",
   "metadata": {},
   "source": [
    "Para realizar las predicciones, podemos ejecutar el fichero ***predict.py***, en el que tiene que estar en sintonía, el modelo que se cargue con los parámetros establecidos en ***config.py*** ya que con ello buscará la carpeta correspondiente, pero tendremos que indicar qué modelo que queremos, es decir, el que se encuentre dentro de los modelos guardados de este en la carpeta ***models***.\n",
    "\n",
    "Se realizan las prediciones sobre las imagenes y vídeos que se encuentran dentro de la carpeta de ***test*** y el resultado de predecir se encontrará dentro de la carpeta que haga referencia al modelo que estamos ejecutando.\n",
    "\n",
    "Las pruebas de test que se han realizado con:\n",
    "* Imagenes de test del dataset de **Airbus Aircraft**\n",
    "* Video sobre las imagenes de tesst de **Airbus Aircraft**, en el que se ha hecho zoom in y out\n",
    "* Video sobre el **aeropuerto de Barajas** y el **aeropuerto de Barcelona**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6d6a1-9876-48bf-8a46-da8bf227bd49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Configuration Summary:\n",
      "  Dataset: Airbus_256_2\n",
      "  Backbone: bedmodel (Not Pretrained)\n",
      "  Batch Size: 32\n",
      "  Optimizer: NAdam\n",
      "  Learning Rate Scheduler: None\n",
      "  Number of Classes: 1\n",
      "  Image Size: 224\n",
      "Summary saved to /home/jovyan/Carlos_Gonzalez/YOLO/bedmodel/NAdam_None_Airbus_256_2_BATCH_32_LR_0.0005/model_summary.txt\n",
      "bedmodel | Parameters: 718008 | Size: 2.80 MB\n",
      "Epoch [0/59]: 100%|██████████████████| 329/329 [00:21<00:00, 15.04it/s, loss=67]\n",
      "---------------------------------------------------\n",
      "-----------Loss Summary during training------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "172.387     |103.450     |21.242      |17.454      |3.626       |\n",
      "---------------------------------------------------\n",
      "Eval: Train: : 100%|██████████████████████████| 330/330 [00:26<00:00, 12.60it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "48.656      |27.700      |19.696      |1.359       |0.259       |\n",
      "---------------------------------------------------\n",
      "Train: \t mAP@50: 0.020643, mAP@75: 0.006985, mAP@90: 0.000042, Mean Loss: 48.656407\n",
      "Eval: Valid: : 100%|████████████████████████████| 92/92 [00:06<00:00, 13.39it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "50.101      |28.220      |20.213      |1.375       |0.292       |\n",
      "---------------------------------------------------\n",
      "Valid: \t mAP@50: 0.030167, mAP@75: 0.005566, mAP@90: 0.000047, Mean Loss: 50.100910\n",
      "----------------------------------------\n",
      "Epoch: 0 |Train mAP: 0.020643 |Validation mAP: 0.030167\n",
      "----------------------------------------\n",
      "time: 57.66908049583435\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Epoch [1/59]: 100%|████████████████| 329/329 [00:23<00:00, 14.00it/s, loss=93.4]\n",
      "---------------------------------------------------\n",
      "-----------Loss Summary during training------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "74.587      |30.720      |18.017      |3.053       |0.575       |\n",
      "---------------------------------------------------\n",
      "Eval: Train: : 100%|██████████████████████████| 330/330 [00:25<00:00, 12.73it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "41.978      |22.380      |17.764      |1.801       |0.111       |\n",
      "---------------------------------------------------\n",
      "Train: \t mAP@50: 0.077549, mAP@75: 0.038358, mAP@90: 0.000812, Mean Loss: 41.978069\n",
      "Eval: Valid: : 100%|████████████████████████████| 92/92 [00:06<00:00, 13.92it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "44.018      |23.947      |18.186      |1.763       |0.122       |\n",
      "---------------------------------------------------\n",
      "Valid: \t mAP@50: 0.073576, mAP@75: 0.020901, mAP@90: 0.000226, Mean Loss: 44.018042\n",
      "----------------------------------------\n",
      "Epoch: 1 |Train mAP: 0.077549 |Validation mAP: 0.073576\n",
      "----------------------------------------\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "time: 60.169246673583984\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Epoch [2/59]: 100%|████████████████| 329/329 [00:20<00:00, 15.97it/s, loss=52.2]\n",
      "---------------------------------------------------\n",
      "-----------Loss Summary during training------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "64.601      |26.046      |16.450      |3.137       |0.418       |\n",
      "---------------------------------------------------\n",
      "Eval: Train: : 100%|██████████████████████████| 330/330 [00:24<00:00, 13.43it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "43.711      |26.388      |17.725      |1.143       |0.062       |\n",
      "---------------------------------------------------\n",
      "Train: \t mAP@50: 0.050638, mAP@75: 0.003412, mAP@90: 0.000013, Mean Loss: 43.711289\n",
      "Eval: Valid: : 100%|████████████████████████████| 92/92 [00:07<00:00, 12.68it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "49.063      |29.254      |18.620      |1.124       |0.064       |\n",
      "---------------------------------------------------\n",
      "Valid: \t mAP@50: 0.037581, mAP@75: 0.002374, mAP@90: 0.000000, Mean Loss: 49.062557\n",
      "----------------------------------------\n",
      "Epoch: 2 |Train mAP: 0.050638 |Validation mAP: 0.037581\n",
      "----------------------------------------\n",
      "=> Saving checkpoint\n",
      "time: 55.94391989707947\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Epoch [3/59]: 100%|██████████████████| 329/329 [00:21<00:00, 15.46it/s, loss=57]\n",
      "---------------------------------------------------\n",
      "-----------Loss Summary during training------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "58.391      |23.842      |15.482      |3.273       |0.402       |\n",
      "---------------------------------------------------\n",
      "Eval: Train: : 100%|██████████████████████████| 330/330 [00:24<00:00, 13.28it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "51.029      |30.682      |19.057      |1.176       |0.082       |\n",
      "---------------------------------------------------\n",
      "Train: \t mAP@50: 0.014905, mAP@75: 0.000006, mAP@90: 0.000000, Mean Loss: 51.028818\n",
      "Eval: Valid: : 100%|████████████████████████████| 92/92 [00:07<00:00, 12.90it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "52.940      |32.055      |19.688      |1.109       |0.088       |\n",
      "---------------------------------------------------\n",
      "Valid: \t mAP@50: 0.013871, mAP@75: 0.000020, mAP@90: 0.000000, Mean Loss: 52.939903\n",
      "----------------------------------------\n",
      "Epoch: 3 |Train mAP: 0.014905 |Validation mAP: 0.013871\n",
      "----------------------------------------\n",
      "=> Saving checkpoint\n",
      "time: 55.92678451538086\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Epoch [4/59]: 100%|████████████████| 329/329 [00:21<00:00, 15.00it/s, loss=55.9]\n",
      "---------------------------------------------------\n",
      "-----------Loss Summary during training------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "53.306      |21.968      |14.609      |3.471       |0.392       |\n",
      "---------------------------------------------------\n",
      "Eval: Train: : 100%|██████████████████████████| 330/330 [00:22<00:00, 14.46it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "38.201      |21.057      |15.133      |1.833       |0.138       |\n",
      "---------------------------------------------------\n",
      "Train: \t mAP@50: 0.153975, mAP@75: 0.026546, mAP@90: 0.000066, Mean Loss: 38.201010\n",
      "Eval: Valid: : 100%|████████████████████████████| 92/92 [00:07<00:00, 12.85it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "41.906      |23.743      |16.219      |1.792       |0.152       |\n",
      "---------------------------------------------------\n",
      "Valid: \t mAP@50: 0.109574, mAP@75: 0.014133, mAP@90: 0.000002, Mean Loss: 41.905843\n",
      "----------------------------------------\n",
      "Epoch: 4 |Train mAP: 0.153975 |Validation mAP: 0.109574\n",
      "----------------------------------------\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "time: 57.718177795410156\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Epoch [5/59]: 100%|████████████████| 329/329 [00:22<00:00, 14.43it/s, loss=36.5]\n",
      "---------------------------------------------------\n",
      "-----------Loss Summary during training------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "49.361      |20.398      |14.074      |3.526       |0.395       |\n",
      "---------------------------------------------------\n",
      "Eval: Train: : 100%|██████████████████████████| 330/330 [00:25<00:00, 13.12it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "31.078      |14.600      |12.874      |2.823       |0.133       |\n",
      "---------------------------------------------------\n",
      "Train: \t mAP@50: 0.272767, mAP@75: 0.111944, mAP@90: 0.001848, Mean Loss: 31.078077\n",
      "Eval: Valid: : 100%|████████████████████████████| 92/92 [00:07<00:00, 12.76it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "33.792      |17.290      |13.644      |2.716       |0.141       |\n",
      "---------------------------------------------------\n",
      "Valid: \t mAP@50: 0.250358, mAP@75: 0.111297, mAP@90: 0.000228, Mean Loss: 33.791509\n",
      "----------------------------------------\n",
      "Epoch: 5 |Train mAP: 0.272767 |Validation mAP: 0.250358\n",
      "----------------------------------------\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "time: 64.21174454689026\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Epoch [6/59]: 100%|████████████████| 329/329 [00:23<00:00, 14.24it/s, loss=39.9]\n",
      "---------------------------------------------------\n",
      "-----------Loss Summary during training------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "46.447      |19.472      |13.344      |3.682       |0.383       |\n",
      "---------------------------------------------------\n",
      "Eval: Train: : 100%|██████████████████████████| 330/330 [00:24<00:00, 13.47it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "28.270      |14.118      |12.631      |2.680       |0.165       |\n",
      "---------------------------------------------------\n",
      "Train: \t mAP@50: 0.285909, mAP@75: 0.130637, mAP@90: 0.001687, Mean Loss: 28.269965\n",
      "Eval: Valid: : 100%|████████████████████████████| 92/92 [00:06<00:00, 14.10it/s]\n",
      "---------------------------------------------------\n",
      "-------------Loss Summary eval {mode}--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "32.661      |16.490      |13.401      |2.592       |0.179       |\n",
      "---------------------------------------------------\n",
      "Valid: \t mAP@50: 0.263941, mAP@75: 0.111595, mAP@90: 0.000938, Mean Loss: 32.661032\n",
      "----------------------------------------\n",
      "Epoch: 6 |Train mAP: 0.285909 |Validation mAP: 0.263941\n",
      "----------------------------------------\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "time: 62.4671151638031\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Epoch [7/59]:  53%|████████▍       | 173/329 [00:11<00:10, 14.56it/s, loss=57.2]"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566a3efb-7e41-4076-b791-931244ef804c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Configuration Summary:\n",
      "  Dataset: Airbus_256_2\n",
      "  Backbone: bedmodel (Not Pretrained)\n",
      "  Batch Size: 32\n",
      "  Optimizer: Adam\n",
      "  Learning Rate Scheduler: None\n",
      "  Number of Classes: 1\n",
      "  Image Size: 224\n",
      "Summary saved to /home/jovyan/Carlos_Gonzalez/YOLO/bedmodel/Adam_None_Airbus_256_2_BATCH_32_LR_0.0005/model_summary.txt\n",
      "bedmodel | Parameters: 718008 | Size: 2.80 MB\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/Carlos_Gonzalez/YOLO/train.py\", line 326, in <module>\n",
      "    main()\n",
      "  File \"/home/jovyan/Carlos_Gonzalez/YOLO/train.py\", line 215, in main\n",
      "    load_checkpoint(torch.load(os.path.join(config.DRIVE_PATH,f'{config.BACKBONE}/{config.TOTAL_PATH}/model/YOLO_epoch_{initial_epoch}.pth.tar')), model, optimizer)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/serialization.py\", line 997, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/serialization.py\", line 444, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/serialization.py\", line 425, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/jovyan/Carlos_Gonzalez/YOLO/bedmodel/Adam_None_Airbus_256_2_BATCH_32_LR_0.0005/model/YOLO_epoch_52.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59716121-ae47-4b18-ad67-affa655eb5fd",
   "metadata": {},
   "source": [
    "Tenemos varias sistuaciones, en las que podemos hacer inferencia, tenemos imagenes y vídeos, las imagenes escogidas son con las que contamos en la carpeta de **test** de **Airbus**, se ha establecido que para independientemente del modelo, si la imagen es más pequeña o igual a 256x256 pixeles se les haga un resize, y posteriormente es procesada por el modelo. Pero nos encontramos cno un problema de detección en imagnens satelitales en las que las imagenes son de 2560x2560 pixeles, por tanto hay que utilizar una técnica que en inglés se llama *tiles*. \n",
    "\n",
    "Esta técnica de *tiles* tiene como objetivo subdividir la imagen en cuadrados, en nuestro caso de 256 pixeles, pero, utilizamos una técnica de solapamiento o *overlap* de los *tiles* para conseguir recorrer la imagen con éxito. Es decir, el cuadrado anterior de 256x256 pixeles y el nuevo se solapan un cierto porcentaje, en nuestro caso, un 20%. Esto supone obtener muchas Boundary Boxes, por ello, posteriormente a esto hay que utilizar la técnica de Non Max Supression que permite la eliminación de Boundary Boxes que se solapan un cierto porcentaje, esto se especifica con el parámetro *Intersection Over Union*, **IOU**, además hay otro parámetro, ***threshold** que se utiliza para eliminar las Boundary Boxes que haya sido evaluado por el modelo con nivel de confianza bajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d943b5b9-ea08-4a15-b5a7-ff896a268b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the folder that needs to be zipped\n",
    "folder_path = '/home/jovyan/Carlos_Gonzalez/YOLO/efficientnet/Adam_None_2Airbus_256_BATCH_32_LR_0.0005/test'\n",
    "\n",
    "# Path for the output zip file\n",
    "zip_file_path = '/home/jovyan/Carlos_Gonzalez/YOLO/efficientnet/Adam_None_2Airbus_256_BATCH_32_LR_0.0005/test.zip'\n",
    "\n",
    "# Create a ZipFile object in WRITE mode\n",
    "with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Walk through directory\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Create a relative path for files to keep the directory structure\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), os.path.join(folder_path, '..'))\n",
    "            zipf.write(os.path.join(root, file), relative_path)\n",
    "\n",
    "# Verify if file was created successfully\n",
    "os.path.exists(zip_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b90396-1168-41b0-b724-3c2266a1201e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
