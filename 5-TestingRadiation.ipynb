{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9faeac2a-7873-4028-82cb-a4f525882b10",
   "metadata": {},
   "source": [
    "# **Libraries Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cde9c7-2668-41ff-ae2f-b4f1aa0ced51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "!pip install torchmetrics\n",
    "!pip install torchvision\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf1687a-97c1-44a3-9e02-1a2d83bfc5af",
   "metadata": {},
   "source": [
    "# **Testing Noise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e60e97-2d9f-4879-9051-350228034849",
   "metadata": {},
   "source": [
    "One of the objectives of this project is the subsequent implementation of these models in an FPGA, in order to be able to solve detection problems from a satellite.\n",
    "\n",
    "It is known that the models in an FPGA are exposed to noise, this noise can affect any part of the model, the following cases have been considered:\n",
    "* **Case 1**: it is intended to simulate the noise that can occur within the model, i.e. between layer connections. Phenomenon known as SEU.\n",
    "* **Case 2**: noise that may affect the weights of the model due to fluctuations that may arise in the storage of these is simulated. Phenomenon known as SEL.\n",
    "\n",
    "For case 1 and 2 of noise analysis, we have considered the case that if noise exists, it produces a bit-flip at some random point of the weights or activations.\n",
    "\n",
    "In this ***Notebook*** it is intended to analyse different cases, how the different noises are affected in isolation. The results obtained are saved in the corresponding folder of the model being executed, in the ***results_noise*** subfolder, in which the loss and mAP50 metrics are analysed.\n",
    "\n",
    "As in the previous ***Notebooks***, the execution of these codes depends directly on the configuration file ***config.py***, for the selection of the model. In this notebook, unlike the others, we do not execute the code with a !python eval_noise.py, but we do an import, for convenience of this code and to be able to evaluate the different cases. This being the code, if you want to test different models with the ***config.py*** file, you have to restart the kernel after modifying the file.\n",
    "\n",
    "If you want to test **noise.py** on the optimised models, you have to specify the path of the optimised model, but it has to be consistent with **config.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c95d4-4278-44cc-8490-970d8c2151e9",
   "metadata": {},
   "source": [
    "# Analysis for the model with maximum accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b614bc-4304-4086-8e39-0550473aadfc",
   "metadata": {},
   "source": [
    "For each of the cases, different noise levels have to be introduced, from low levels to progressively higher levels. Keep in mind that in each case, the model is influenced in one way or another, so these noise levels have different levels in each of them.\n",
    "\n",
    "Keep in mind that the higher the number of slices, the less layers we have in each slice, and therefore, to make sure that the layers are really affected, a higher percentage should be selected.\n",
    "\n",
    "\n",
    "You can select the slice you want to be modified\n",
    "With this parameter we select the area in which we want to affect the activations or weights\n",
    "i.e. slices = [slice_i, n_slices], with this we divide all the layers in n_slices and we affect the layers that are in slice_i.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  |slice 0 | slice 1 | slice 2 | slice 3 | slice4\n",
    "\n",
    "if slice_i = n_slices is selected, we traverse from slice_0,, to slice_n-1.\n",
    "\n",
    "Then there is the parameter **percentage_layers_case1** which is an array of percentages. For each activation (LeakyRelu or Relu) (case1) or weight (case2) of each slice, a random number is calculated and if it is less than the corresponding percentage of the array, that layer will suffer the effect of the bit flip. On the other hand, as the weights and activations are a set of tensors, the parameter **percentage_tensor** determines the percentage of tensors that are affected in that layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1dbed4-dfcd-42dd-acc5-bca458dfc1d4",
   "metadata": {},
   "source": [
    "## **Test case1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4180f-40dc-490c-bb72-fdd9a21d0378",
   "metadata": {},
   "source": [
    "As we divide the outputs of the activation functions into 3 blocks, a percentage of affected tensors/parameters is selected for each case. \n",
    "* Block 1: the activation functions have $10^6$ order parameters, so a selection of 0.05% of affected parameters is reasonable.\n",
    "* Block 2: the activation functions are of order $10^5$ and $10^4$, here a higher percentage of affected parameters has been selected, 0.5\\%.\n",
    "* Block 3: the activation functions are of order $10^4$ and $10^3$, in this situation 5% of affected parameters are selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1d1d3d-5f2d-4503-ba84-edd6d0b4023b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=True\n",
    "case2=False\n",
    "percentage_layers_case_1  = [0, 0.3, 0.5, 0.7, 1] if case1 else [0]\n",
    "\n",
    "#prueba 1\n",
    "slices_case1 = [1,1]\n",
    "interval_1 = (-23,2)\n",
    "percentage_tensors_1 = 0.05\n",
    "\n",
    "test_noise( case1=case1, percentage_layers_case_1=percentage_layers_case_1, slices_case1 = slices_case1, interval_1 = interval_1, percentage_tensors_1=percentage_tensors_1,\n",
    "            case2=case2, percentage_layers_case_2=[0], slices_case2 = [0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c9b09-32d4-4e4e-b533-35f688263f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=True\n",
    "case2=False\n",
    "percentage_layers_case_1  = [0, 0.3, 0.5, 0.7, 1] if case1 else [0]\n",
    "\n",
    "#prueba 1\n",
    "slices_case1 = [1,1]\n",
    "interval_1 = (-2,2)\n",
    "percentage_tensors_1 = 0.05\n",
    "\n",
    "test_noise( case1=case1, percentage_layers_case_1=percentage_layers_case_1, slices_case1 = slices_case1, interval_1 = interval_1, percentage_tensors_1=percentage_tensors_1,\n",
    "            case2=case2, percentage_layers_case_2=[0], slices_case2 = [0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb74ed-e8cc-49b6-be06-94b0997143e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=True\n",
    "case2=False\n",
    "percentage_layers_case_1  = [0, 0.5, 1] if case1 else [0]\n",
    "\n",
    "#prueba 1\n",
    "slices_case1 = [3,3]\n",
    "interval_1 = (-32,2)\n",
    "percentage_tensors_1 = 0.05\n",
    "\n",
    "test_noise( case1=case1, percentage_layers_case_1=percentage_layers_case_1, slices_case1 = slices_case1, interval_1 = interval_1, percentage_tensors_1=percentage_tensors_1,\n",
    "            case2=case2, percentage_layers_case_2=[0], slices_case2 = [0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ebcec-11a9-47f2-8f19-f97c4709c4bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=True\n",
    "case2=False\n",
    "percentage_layers_case_1  = [0, 0.5, 1] if case1 else [0]\n",
    "\n",
    "#prueba 1\n",
    "slices_case1 = [3,3]\n",
    "interval_1 = (-2,2)\n",
    "percentage_tensors_1 = 0.05\n",
    "\n",
    "test_noise( case1=case1, percentage_layers_case_1=percentage_layers_case_1, slices_case1 = slices_case1, interval_1 = interval_1, percentage_tensors_1=percentage_tensors_1,\n",
    "            case2=case2, percentage_layers_case_2=[0], slices_case2 = [0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be62cda3-d741-4ae4-88ba-3ebdfeae3848",
   "metadata": {},
   "source": [
    "## **Test case 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a57736-b45d-4248-bc17-8c9a65deb732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=False\n",
    "case2=True\n",
    "percentage_layers_case_2 = [0, 0.3, 0.5, 0.7, 1] if case2 else [0]\n",
    "\n",
    "#prueba 4\n",
    "slices_case2 = [1,1]\n",
    "interval_2 = (-32,2)\n",
    "percentage_tensors_2 = 0.0001\n",
    "\n",
    "test_noise( case1=case1, percentage_layers_case_1=[0], slices_case1 = [0,0],\n",
    "           case2=case2, percentage_layers_case_2=percentage_layers_case_2, slices_case2 = slices_case2, interval_2 = interval_2, percentage_tensors_2= percentage_tensors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6dc2ee1-17d3-4eb1-955d-9635574dab13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test with case1: False, case2: True\n",
      "Results will be saved in: case2_results_noise_slices_1_interval2_-2_2_p_0.003.txt\n",
      "=> Loading checkpoint\n",
      "Model loaded: tinyissimoYOLO/NAdam_None_Airbus_256_BATCH_32_LR_0.0005/model/19_YOLO_best.pth.tar\n",
      "############################################\n",
      "Noise level 2: Slice: [1, 1], Percentage: 0\n",
      "############################################\n",
      "=> Loading checkpoint\n",
      "Model loaded: tinyissimoYOLO/NAdam_None_Airbus_256_BATCH_32_LR_0.0005/model/19_YOLO_best.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: Valid: :  43%|████▎     | 40/92 [00:01<00:01, 34.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "-------------Loss Summary eval Valid--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "12.858      |6.270       |4.544       |1.968       |0.076       |\n",
      "---------------------------------------------------\n",
      "Valid: \t mAP@50: 0.749606, mAP@75: 0.347025, mAP@90: 0.003100, Mean Loss: 12.858233\n",
      "=> Loading checkpoint\n",
      "Model loaded: tinyissimoYOLO/NAdam_None_Airbus_256_BATCH_32_LR_0.0005/model/19_YOLO_best.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: Valid: :  43%|████▎     | 40/92 [00:01<00:01, 32.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "-------------Loss Summary eval Valid--------------\n",
      "Total Loss  |Loss Coord  |Conf Loss   |No Obj Loss |Class Loss  |\n",
      "14.521      |6.978       |5.407       |2.041       |0.096       |\n",
      "---------------------------------------------------\n",
      "Valid: \t mAP@50: 0.699511, mAP@75: 0.304510, mAP@90: 0.004217, Mean Loss: 14.520915\n",
      "=> Loading checkpoint\n",
      "Model loaded: tinyissimoYOLO/NAdam_None_Airbus_256_BATCH_32_LR_0.0005/model/19_YOLO_best.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: Valid: :  37%|███▋      | 34/92 [00:01<00:01, 32.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m interval_2 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      9\u001b[0m percentage_tensors_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.003\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtest_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercentage_layers_case_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslices_case1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m           \u001b[49m\u001b[43mcase2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercentage_layers_case_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentage_layers_case_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslices_case2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mslices_case2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval_2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterval_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercentage_tensors_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpercentage_tensors_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Carlos_Gonzalez/newYOLO/radiation/eval_noise.py:139\u001b[0m, in \u001b[0;36mtest_noise\u001b[0;34m(case1, percentage_layers_case_1, slices_case1, interval_1, percentage_tensors_1, case2, percentage_layers_case_2, slices_case2, interval_2, percentage_tensors_2, folder_model, debug)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#       Evaluating for valid               #\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[1;32m    137\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 139\u001b[0m pred_boxes, target_boxes, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_bboxes_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m val_mAP_50, val_mAP_75, val_mAP_90 \u001b[38;5;241m=\u001b[39m mean_average_precision_noise(pred_boxes, target_boxes, iou_thresholds\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;241m0.9\u001b[39m], box_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmidpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mNUM_CLASSES, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid: \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m mAP@50: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_mAP_50\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mAP@75: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_mAP_75\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mAP@90: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_mAP_90\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Mean Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Carlos_Gonzalez/newYOLO/utils/utils.py:520\u001b[0m, in \u001b[0;36mget_bboxes_noise\u001b[0;34m(loader, model, loss_fn, iou_threshold, threshold, pred_format, box_format, device, mode, add_noise_to_input, noise_level)\u001b[0m\n\u001b[1;32m    517\u001b[0m     mean_loss_class\u001b[38;5;241m.\u001b[39mappend(loss_class\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    519\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 520\u001b[0m true_bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mcellboxes_to_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m cellboxes_to_boxes(predictions)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n",
      "File \u001b[0;32m~/Carlos_Gonzalez/newYOLO/utils/utils.py:623\u001b[0m, in \u001b[0;36mcellboxes_to_boxes\u001b[0;34m(out)\u001b[0m\n\u001b[1;32m    620\u001b[0m     bboxes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bbox_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mSPLIT_SIZE \u001b[38;5;241m*\u001b[39m config\u001b[38;5;241m.\u001b[39mSPLIT_SIZE):\n\u001b[0;32m--> 623\u001b[0m         bboxes\u001b[38;5;241m.\u001b[39mappend([x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m converted_pred[ex_idx, bbox_idx, :]])\n\u001b[1;32m    624\u001b[0m     all_bboxes\u001b[38;5;241m.\u001b[39mappend(bboxes)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_bboxes\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:1037\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1028\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing len to get tensor shape might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1029\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommended usage would be tensor.shape[0]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1033\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1034\u001b[0m         )\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m# save us work, and also helps keep trace ordering deterministic\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# (e.g., if you zip(*hiddens), the eager map will force all the\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# indexes of hiddens[0] before hiddens[1], while the generator\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;66;03m# map will interleave them.)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# See gh-54457\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration over a 0-d tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=False\n",
    "case2=True\n",
    "percentage_layers_case_2 = [0, 0.3, 0.5, 0.7, 1] if case2 else [0]\n",
    "\n",
    "#prueba 4\n",
    "slices_case2 = [1,1]\n",
    "interval_2 = (-2,2)\n",
    "percentage_tensors_2 = 0.003\n",
    "\n",
    "test_noise( case1=case1, percentage_layers_case_1=[0], slices_case1 = [0,0],\n",
    "           case2=case2, percentage_layers_case_2=percentage_layers_case_2, slices_case2 = slices_case2, interval_2 = interval_2, percentage_tensors_2= percentage_tensors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5d0df-0e40-4d56-8484-eed14bfef2fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=False\n",
    "case2=True\n",
    "percentage_layers_case_2 = [0, 0.3, 0.5, 0.7, 1] if case2 else [0]\n",
    "\n",
    "#prueba 4\n",
    "slices_case2 = [3,3]\n",
    "interval_2 = (-32,2)\n",
    "percentage_tensors_2 = 0.001\n",
    "\n",
    "test_noise( case1=case1, percentage_layers_case_1=[0], slices_case1 = [0,0],\n",
    "           case2=case2, percentage_layers_case_2=percentage_layers_case_2, slices_case2 = slices_case2, interval_2 = interval_2, percentage_tensors_2= percentage_tensors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ff247-3de1-4df6-be1d-50c9b1a47dcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=False\n",
    "case2=True\n",
    "percentage_layers_case_2 = [0, 0.3, 0.5, 0.7, 1] if case2 else [0]\n",
    "\n",
    "#prueba 4\n",
    "slices_case2 = [3,3]\n",
    "interval_2 = (-2,2)\n",
    "percentage_tensors_2 = 0.003\n",
    "\n",
    "test_noise( case1=case1, percentage_layers_case_1=[0], slices_case1 = [0,0],\n",
    "           case2=case2, percentage_layers_case_2=percentage_layers_case_2, slices_case2 = slices_case2, interval_2 = interval_2, percentage_tensors_2= percentage_tensors_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b390e-b805-450d-9767-75e67078dd24",
   "metadata": {},
   "source": [
    "# **Analisis for the quantized model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766afc6c-a8c0-4312-b22a-712505abd3fd",
   "metadata": {},
   "source": [
    "## **Test case 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3dfaa-200a-4d93-a7a5-a1d2f00251b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=True\n",
    "case2=False\n",
    "percentage_layers_case_1  = [0, 0.3, 0.5, 0.7, 1] if case1 else [0]\n",
    "\n",
    "#prueba 1\n",
    "slices_case1 = [1,1]\n",
    "interval_1 = (-8,2)\n",
    "percentage_tensors_1 = 0.05\n",
    "\n",
    "folder_model = '5_sims_max_steps_100_slices_3_interval_4_10_degredation_5/sim_1'\n",
    "test_noise( case1=case1, percentage_layers_case_1=percentage_layers_case_1, slices_case1 = slices_case1, interval_1 = interval_1, percentage_tensors_1=percentage_tensors_1,\n",
    "            case2=case2, percentage_layers_case_2=[0], slices_case2 = [0,0],\n",
    "            folder_model = folder_model)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcc0aa-0a87-46a1-ae9e-56ab69a83704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=True\n",
    "case2=False\n",
    "percentage_layers_case_1  = [0, 0.3, 0.5, 0.7, 1] if case1 else [0]\n",
    "\n",
    "#prueba 1\n",
    "slices_case1 = [1,1]\n",
    "interval_1 = (-2,2)\n",
    "percentage_tensors_1 = 0.05\n",
    "\n",
    "folder_model = '5_sims_max_steps_100_slices_3_interval_4_10_degredation_5/sim_1'\n",
    "test_noise( case1=case1, percentage_layers_case_1=percentage_layers_case_1, slices_case1 = slices_case1, interval_1 = interval_1, percentage_tensors_1=percentage_tensors_1,\n",
    "            case2=case2, percentage_layers_case_2=[0], slices_case2 = [0,0],\n",
    "            folder_model = folder_model)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aff974-b397-4364-922e-6ca7c2f4d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=True\n",
    "case2=False\n",
    "percentage_layers_case_1  = [0, 0.5, 1] if case1 else [0]\n",
    "\n",
    "#prueba 1\n",
    "slices_case1 = [3,3]\n",
    "interval_1 = (-32,2)\n",
    "percentage_tensors_1 = 0.05\n",
    "\n",
    "folder_model = '5_sims_max_steps_100_slices_3_interval_4_10_degredation_5/sim_1'\n",
    "test_noise( case1=case1, percentage_layers_case_1=percentage_layers_case_1, slices_case1 = slices_case1, interval_1 = interval_1, percentage_tensors_1=percentage_tensors_1,\n",
    "            case2=case2, percentage_layers_case_2=[0], slices_case2 = [0,0],\n",
    "            folder_model = folder_model)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f6bcb-1f13-4b37-9780-1fe88c7173fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=True\n",
    "case2=False\n",
    "percentage_layers_case_1  = [0, 0.5, 1] if case1 else [0]\n",
    "\n",
    "#prueba 1\n",
    "slices_case1 = [3,3]\n",
    "interval_1 = (-2,2)\n",
    "percentage_tensors_1 = 0.05\n",
    "\n",
    "folder_model = '5_sims_max_steps_100_slices_3_interval_4_10_degredation_5/sim_1'\n",
    "test_noise( case1=case1, percentage_layers_case_1=percentage_layers_case_1, slices_case1 = slices_case1, interval_1 = interval_1, percentage_tensors_1=percentage_tensors_1,\n",
    "            case2=case2, percentage_layers_case_2=[0], slices_case2 = [0,0],\n",
    "            folder_model = folder_model)              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8011de-276b-4061-b044-cf323fdcec67",
   "metadata": {},
   "source": [
    "## **Test case 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f645341-b017-469e-bfd4-d314735c368d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=False\n",
    "case2=True\n",
    "percentage_layers_case_2  = [0, 0.3, 0.5, 0.7, 1] if case2 else [0]\n",
    "\n",
    "\n",
    "#prueba 4\n",
    "slices_case2 = [1,1]\n",
    "interval_2 = (-8,2)\n",
    "percentage_tensors_2 = 0.001\n",
    "\n",
    "folder_model = '5_sims_max_steps_100_slices_3_interval_4_10_degredation_5/sim_1'\n",
    "test_noise( case1=case1, percentage_layers_case_1=[0], slices_case1 = [0,0], \n",
    "            case2=case2, percentage_layers_case_2=percentage_layers_case_2, slices_case2 = slices_case2, interval_2 = interval_2, percentage_tensors_2=percentage_tensors_2,\n",
    "            folder_model = folder_model)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0599f95-49ac-42c8-9f45-96c716c7210c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=False\n",
    "case2=True\n",
    "percentage_layers_case_2  = [0, 0.3, 0.5, 0.7, 1] if case2 else [0]\n",
    "\n",
    "\n",
    "#prueba 4\n",
    "slices_case2 = [1,1]\n",
    "interval_2 = (-2,2)\n",
    "percentage_tensors_2 = 0.003\n",
    "\n",
    "folder_model = '5_sims_max_steps_100_slices_3_interval_4_10_degredation_5/sim_1'\n",
    "test_noise( case1=case1, percentage_layers_case_1=[0], slices_case1 = [0,0], \n",
    "            case2=case2, percentage_layers_case_2=percentage_layers_case_2, slices_case2 = slices_case2, interval_2 = interval_2, percentage_tensors_2=percentage_tensors_2,\n",
    "            folder_model = folder_model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eaf127-04d0-4528-aa4f-c18597c81f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=False\n",
    "case2=True\n",
    "percentage_layers_case_2  = [0, 0.3, 0.5, 0.7, 1] if case2 else [0]\n",
    "\n",
    "\n",
    "#prueba 4\n",
    "slices_case2 = [3,3]\n",
    "interval_2 = (-8,2)\n",
    "percentage_tensors_2 = 0.001\n",
    "\n",
    "folder_model = '5_sims_max_steps_100_slices_3_interval_4_10_degredation_5/sim_1'\n",
    "test_noise( case1=case1, percentage_layers_case_1=[0], slices_case1 = [0,0], \n",
    "            case2=case2, percentage_layers_case_2=percentage_layers_case_2, slices_case2 = slices_case2, interval_2 = interval_2, percentage_tensors_2=percentage_tensors_2,\n",
    "            folder_model = folder_model)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe3180-acd5-4d44-8dff-df6d17ca6dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=False\n",
    "case2=True\n",
    "percentage_layers_case_2  = [0, 0.3, 0.5, 0.7, 1] if case2 else [0]\n",
    "\n",
    "\n",
    "#prueba 4\n",
    "slices_case2 = [3,3]\n",
    "interval_2 = (-2,2)\n",
    "percentage_tensors_2 = 0.003\n",
    "\n",
    "folder_model = '5_sims_max_steps_100_slices_3_interval_4_10_degredation_5/sim_1'\n",
    "test_noise( case1=case1, percentage_layers_case_1=[0], slices_case1 = [0,0], \n",
    "            case2=case2, percentage_layers_case_2=percentage_layers_case_2, slices_case2 = slices_case2, interval_2 = interval_2, percentage_tensors_2=percentage_tensors_2,\n",
    "            folder_model = folder_model)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264dd5b4-dffa-441f-9679-7a6a8de090d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from radiation.eval_radiation import test_noise\n",
    "case1=False\n",
    "case2=True\n",
    "percentage_layers_case_2  = [0, 0.3, 0.5, 0.7, 1] if case2 else [0]\n",
    "\n",
    "\n",
    "#prueba 4\n",
    "slices_case2 = [3,3]\n",
    "interval_2 = (-4,2)\n",
    "percentage_tensors_2 = 0.003\n",
    "\n",
    "folder_model = '5_sims_max_steps_100_slices_3_interval_4_10_degredation_5/sim_1'\n",
    "test_noise( case1=case1, percentage_layers_case_1=[0], slices_case1 = [0,0], \n",
    "            case2=case2, percentage_layers_case_2=percentage_layers_case_2, slices_case2 = slices_case2, interval_2 = interval_2, percentage_tensors_2=percentage_tensors_2,\n",
    "            folder_model = folder_model)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
