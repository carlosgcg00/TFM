{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG3RHcGwgJso"
   },
   "source": [
    "## **YOLO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwsmMMxDd-iF"
   },
   "source": [
    "Tutorial Link: https://www.youtube.com/watch?v=m9fH9OWn8YM\n",
    "\n",
    "GitHub Repository: https://github.com/ultralytics/ultralytics\n",
    "\n",
    "As previously mentioned, we will be utilizing the Airbus Aircraft database, which features high-resolution satellite images, each measuring 2560x2560 pixels.\n",
    "\n",
    "However, according to the documentation on the YOLO library's GitHub page, the latest models in this library are not capable of processing images larger than 640 pixels. Consequently, in this section of our project, we have decided to divide the image in subimages, i.e., instead of having one picture of 2560x2560 there is gonna be 25 subimages of 512x512 pixels.\n",
    "\n",
    "As we are using the YOLO files, we do not only need to make the image divisionwe also need to prepare the files for those subimages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNTf7HliKNhi"
   },
   "source": [
    "There are many versions of YOLO, but we will focus on YOLOv8, which are the latest versions offered. Additionally, within YOLOv8, there are several models that have been pre-trained for Detection, Segmentation, and Pose with different databases. Among the different databases used, it's worth highlighting COCO (Common Objects in Context), Open Image V7 (with Google Images), and ImageNet, each of which includes labeled images [6].\n",
    "Focusing exclusively on YOLOv8 pre-trained with COCO, we need to choose a model size that is suitable for the problem at hand. The following table shows a summary of the main characteristics of the different models. Notable features include the pixel size that the model supports, params which is the number of parameters the model has in millions (a higher number of parameters can be more complex and effective, but slower), and lastly FLOPs (Floating Point Operations Per Second) representing the model's complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzb0o9HreDbM"
   },
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTvbhWN3g7V1"
   },
   "source": [
    "YOLO = You only see once\n",
    "\n",
    "COCO = Common Objects in Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHzUNUkWeVDJ"
   },
   "source": [
    "# **Installation Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ETGjr6jfJ_g",
    "outputId": "6186f774-6953-4248-fe9f-d29c067a3a27",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ultralytics in /opt/conda/lib/python3.11/site-packages (8.2.14)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (10.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (1.11.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.3.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2023.5.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.3.101)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Jup8mYWzCPlY"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnyx7eQLeYzT"
   },
   "source": [
    "# **Acces to Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Su-YRNv-h3hp",
    "outputId": "6b3db733-04cd-4765-f665-1217c92fa609"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fk5Cyk7Mhe4O"
   },
   "source": [
    "Se puede escoger el modelo con el que queremos entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCi-PIphfBBH"
   },
   "source": [
    "# **Train and Test Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Tmr4Axx7f89q"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOLkHOlZlTbT"
   },
   "source": [
    "## Config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOvH8fH-kozp"
   },
   "source": [
    "For the model.train function of the library YOLO we need to give as an input the model we want to use, as well as, the config_file.\n",
    "\n",
    "To verify that everything it is correct we are going to create a function that verifies if that configuration file exists or not, if not create it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIti4HkBlWeP"
   },
   "source": [
    "## Train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfjbzD2plbU0"
   },
   "source": [
    "We need to select a YOLO model to train our data.\n",
    "\n",
    "In this project we selected the yolov8n, as it had provided the best results to this data. There is the need to point it out, that this model is a pretrained model, hence, it will may probably improve the  model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "mhIvkSF7fgUu",
    "outputId": "b90d0d13-597d-4b07-9d0d-a23190f60dcb"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yoUbFbtetGo",
    "outputId": "b6f072c3-a62d-467d-8a1a-b2d0b59f0330"
   },
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GMX6IpOgT51",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.14 🚀 Python-3.11.4 torch-2.3.0+cu121 CUDA:0 (NVIDIA A100-PCIE-40GB MIG 7g.40gb, 40326MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/home/jovyan/Carlos_Gonzalez/YOLO/Airbus/Airbus.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train52, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train52\n",
      "Overriding model.yaml nc=20 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train52', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/jovyan/Carlos_Gonzalez/YOLO/Airbus/labels/train.cache... 2399 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2399/2399 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jovyan/Carlos_Gonzalez/YOLO/Airbus/labels/valid.cache... 878 images, 249 backgrounds, 0 corrupt: 100%|██████████| 878/878 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train52/labels.jpg... \n"
     ]
    }
   ],
   "source": [
    "results = model.train(data = path+ 'Datasets/Airbus/Airbus.yaml', epochs = 10,  imgsz=512, save = True, val = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (11): ZeroPad2d((0, 1, 0, 1))\n",
       "      (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (13): Conv(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (14): Conv(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (15): Conv(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (18): Concat()\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0b1irQKKfcX"
   },
   "outputs": [],
   "source": [
    "f1_curve_img = Image.open('/content/runs/detect/train/F1_curve.png')\n",
    "PR_curve_img = Image.open('/content/runs/detect/train/PR_curve.png')\n",
    "\n",
    "os.makedirs(path+'Results/image_dividing', exist_ok=True)\n",
    "\n",
    "f1_curve_img.save(path+'Results/image_dividing/yolov8n_F1_curve.png')\n",
    "PR_curve_img.save(path+'Results/image_dividing/yolov8n_PR_curve.png')\n",
    "\n",
    "# display(f1_curve_img)\n",
    "# display(PR_curve_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqKv1Z2FmJIg"
   },
   "source": [
    "Once, the pretrained model is trained and tested, all of it will be saved in this local path. (In this case, as I am using Google Colab is it save in this Notebook, although if we want it we can export it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0688Lc_pKXYu",
    "outputId": "08bb01d6-243a-45bb-b829-d343d93be7d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.237 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/Othercomputers/Mi portátil (1)/Erasmus/Ljubljana/Subjects/Artificial Intelligence Systems/AirbusAircraft/archive/config_image_dividing.yaml, epochs=10, time=None, patience=50, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136374 parameters, 11136358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/Othercomputers/Mi portátil (1)/Erasmus/Ljubljana/Subjects/Artificial Intelligence Systems/AirbusAircraft/archive/data_YOLO2_image_dividing/labels/train.cache... 1800 images, 1289 backgrounds, 0 corrupt: 100%|██████████| 2325/2325 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/Othercomputers/Mi portátil (1)/Erasmus/Ljubljana/Subjects/Artificial Intelligence Systems/AirbusAircraft/archive/data_YOLO2_image_dividing/labels/train.cache... 1800 images, 1289 backgrounds, 0 corrupt: 100%|██████████| 2325/2325 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      2.73G      1.578      2.667      1.475         11        512: 100%|██████████| 146/146 [01:21<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:23<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856       0.34      0.546      0.359      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      2.73G      1.595      1.892      1.504          9        512: 100%|██████████| 146/146 [00:44<00:00,  3.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:22<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.259      0.238      0.139     0.0566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      2.73G        1.6      1.767      1.513          4        512: 100%|██████████| 146/146 [00:44<00:00,  3.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:23<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.452      0.584      0.426      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      2.73G      1.519      1.727      1.441          1        512: 100%|██████████| 146/146 [00:41<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:24<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.499      0.648      0.486      0.285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      2.71G      1.499      1.729       1.43          4        512: 100%|██████████| 146/146 [00:40<00:00,  3.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:24<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.506       0.65      0.495      0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      2.71G      1.438        1.5      1.403          5        512: 100%|██████████| 146/146 [00:42<00:00,  3.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:22<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.531      0.717      0.561      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      2.72G        1.4      1.398      1.363          6        512: 100%|██████████| 146/146 [00:42<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:21<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.515      0.693       0.55      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      2.71G      1.342      1.328      1.334          3        512: 100%|██████████| 146/146 [00:42<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:22<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.566      0.753      0.599      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      2.72G      1.327      1.303      1.327         10        512: 100%|██████████| 146/146 [00:41<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:24<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.598       0.75      0.596      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      2.72G      1.274      1.254      1.276          6        512: 100%|██████████| 146/146 [00:42<00:00,  3.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:23<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.591      0.776      0.638      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.201 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.237 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:25<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.591      0.776      0.638      0.426\n",
      "              Airplane       2325       1473      0.569      0.977      0.732      0.507\n",
      "    Truncated_airplane       2325       1383      0.614      0.575      0.544      0.345\n",
      "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8s.pt') # Use a pretrained model\n",
    "# Use the model\n",
    "results = model.train(data = path+ 'archive/config_image_dividing.yaml', epochs = 10,  imgsz=512, save = True, val = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GsGotjRXd9AX"
   },
   "outputs": [],
   "source": [
    "f1_curve_img = Image.open('/content/runs/detect/train2/F1_curve.png')\n",
    "PR_curve_img = Image.open('/content/runs/detect/train2/PR_curve.png')\n",
    "\n",
    "os.makedirs(path+'Results/image_dividing', exist_ok=True)\n",
    "\n",
    "f1_curve_img.save(path+'Results/image_dividing/yolov8s_F1_curve.png')\n",
    "PR_curve_img.save(path+'Results/image_dividing/yolov8s_PR_curve.png')\n",
    "\n",
    "# display(f1_curve_img)\n",
    "# display(PR_curve_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KT1ErZ1nee21"
   },
   "source": [
    "As we have obtained the best results for yolov8s, we are going to try to improve it with 20 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKuKgpxddwjH"
   },
   "outputs": [],
   "source": [
    "model = YOLO('yolov8s.pt') # Use a pretrained model\n",
    "# Use the model\n",
    "results = model.train(data = path+ 'archive/config_image_dividing.yaml', epochs = 20,  imgsz=512, save = True, val = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BU-BfV5uKfEg"
   },
   "outputs": [],
   "source": [
    "f1_curve_img = Image.open('/content/runs/detect/train3/F1_curve.png')\n",
    "PR_curve_img = Image.open('/content/runs/detect/train3/PR_curve.png')\n",
    "\n",
    "os.makedirs(path+'Results/image_dividing', exist_ok=True)\n",
    "\n",
    "f1_curve_img.save(path+'Results/image_dividing/yolov8s_F1_curve_20_iterations.png')\n",
    "PR_curve_img.save(path+'Results/image_dividing/yolov8s_PR_curve_20_iterations.png')\n",
    "\n",
    "# display(f1_curve_img)\n",
    "# display(PR_curve_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hwit4Gb-ZlJe",
    "outputId": "f72fea31-81b5-4db6-ef87-7bfe833dccb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.237 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/drive/Othercomputers/Mi portátil (1)/Erasmus/Ljubljana/Subjects/Artificial Intelligence Systems/AirbusAircraft/archive/config_image_dividing.yaml, epochs=10, time=None, patience=50, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25857478 parameters, 25857462 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/Othercomputers/Mi portátil (1)/Erasmus/Ljubljana/Subjects/Artificial Intelligence Systems/AirbusAircraft/archive/data_YOLO2_image_dividing/labels/train.cache... 1800 images, 1289 backgrounds, 0 corrupt: 100%|██████████| 2325/2325 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/Othercomputers/Mi portátil (1)/Erasmus/Ljubljana/Subjects/Artificial Intelligence Systems/AirbusAircraft/archive/data_YOLO2_image_dividing/labels/train.cache... 1800 images, 1289 backgrounds, 0 corrupt: 100%|██████████| 2325/2325 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      4.74G      1.558      2.477      1.497         11        512: 100%|██████████| 146/146 [00:58<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:29<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856    0.00121      0.267   0.000765   0.000301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      4.87G       1.72      2.122      1.622          9        512: 100%|██████████| 146/146 [00:53<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:28<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.578      0.369      0.334      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      5.03G      1.655      1.909       1.58          4        512: 100%|██████████| 146/146 [00:52<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:28<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856     0.0158      0.613     0.0148    0.00726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      4.89G      1.605      1.901      1.518          1        512: 100%|██████████| 146/146 [00:53<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:27<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.464      0.655      0.456      0.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      5.01G      1.522       1.83      1.459          4        512: 100%|██████████| 146/146 [00:52<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:27<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.502      0.677      0.498      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      4.89G      1.462      1.577      1.452          5        512: 100%|██████████| 146/146 [00:51<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:27<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.422       0.63      0.453      0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      5.01G      1.434        1.5      1.409          6        512: 100%|██████████| 146/146 [00:51<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:27<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.499      0.676      0.511      0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      4.89G      1.389      1.401      1.371          3        512: 100%|██████████| 146/146 [00:52<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:26<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.547      0.743      0.575      0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      4.86G      1.351      1.381      1.356         10        512: 100%|██████████| 146/146 [00:52<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:26<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.582      0.757      0.577       0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      4.88G      1.284       1.31      1.304          6        512: 100%|██████████| 146/146 [00:51<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:27<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.564      0.751      0.604      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.256 hours.\n",
      "Optimizer stripped from runs/detect/train2/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/train2/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating runs/detect/train2/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.237 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 218 layers, 25840918 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 73/73 [00:29<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2325       2856      0.564      0.752      0.603      0.394\n",
      "              Airplane       2325       1473      0.536      0.976      0.706      0.476\n",
      "    Truncated_airplane       2325       1383      0.591      0.527      0.501      0.312\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8m.pt') # Use a pretrained model\n",
    "# Use the model\n",
    "results = model.train(data = path+ 'archive/config_image_dividing.yaml', epochs = 10,  imgsz=512, save = True, val = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEVRfR8pKfpS"
   },
   "source": [
    "## If there is no Truncated Airplane?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BusCMoDvKjia"
   },
   "source": [
    "We are to train the model onnly to detect Airplanes without differenciating between Airplanes and Truncated Airplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "PGfCBqsxKqrv",
    "outputId": "d2f858cc-4572-43aa-defb-202a0d349f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['path: /content/drive/Othercomputers/Mi portátil (1)/Erasmus/Ljubljana/Subjects/Artificial Intelligence Systems/AirbusAircraft/archive/data_YOLO2_image_dividing_only_airplanes', '\\ntrain: images/train', '\\nval: images/train', '\\nnames:\\n  0: Airplane']\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/Othercomputers/Mi portátil (1)/Erasmus/Ljubljana/Subjects/Artificial Intelligence Systems/AirbusAircraft/archive/config_image_dividing_only_airplanes.yaml'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_store = 'data_YOLO2_image_dividing_only_airplanes'\n",
    "name_classes = ['Airplane']\n",
    "config_file(path+'archive','config_image_dividing_only_airplanes.yaml', path_data_store, name_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kbeOiHo0F1hg",
    "outputId": "60d1c411-1130-4674-ce59-9e21786c2d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /content/drive/Othercomputers/Mi portátil (1)/Erasmus/Ljubljana/Subjects/Artificial Intelligence Systems/AirbusAircraft/archive/data_YOLO2_image_dividing_only_airplanes\n",
      "train: images/train\n",
      "val: images/train\n",
      "names:\n",
      "  0: Airplane\n"
     ]
    }
   ],
   "source": [
    "with open(path+\"archive/config_image_dividing_only_airplanes.yaml\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RSj5QwAK74D"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data = path+ 'archive/config_image_dividing_only_airplanes.yaml', epochs = 10,  imgsz=512, save = True, val = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRIX7z9veF2V"
   },
   "outputs": [],
   "source": [
    "f1_curve_img = Image.open('/content/runs/detect/train5/F1_curve.png')\n",
    "PR_curve_img = Image.open('/content/runs/detect/train5/PR_curve.png')\n",
    "\n",
    "os.makedirs(path+'Results/image_dividing_only_airplanes', exist_ok=True)\n",
    "\n",
    "f1_curve_img.save(path+'Results/image_dividing_only_airplanes/yolov8m_F1_curve.png')\n",
    "PR_curve_img.save(path+'Results/image_dividing_only_airplanes/yolov8m_PR_curve.png')\n",
    "\n",
    "# display(f1_curve_img)\n",
    "# display(PR_curve_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rETMufYK-J9"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data = path+ 'archive/config_image_dividing_only_airplanes.yaml', epochs = 10,  imgsz=512, save = True, val = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_xMGWAuePw0"
   },
   "outputs": [],
   "source": [
    "f1_curve_img = Image.open('/content/runs/detect/train5/F1_curve.png')\n",
    "PR_curve_img = Image.open('/content/runs/detect/train5/PR_curve.png')\n",
    "\n",
    "os.makedirs(path+'Results/image_dividing_only_airplanes', exist_ok=True)\n",
    "\n",
    "f1_curve_img.save(path+'Results/image_dividing_only_airplanes/yolov8s_F1_curve.png')\n",
    "PR_curve_img.save(path+'Results/image_dividing_only_airplanes/yolov8s_PR_curve.png')\n",
    "\n",
    "# display(f1_curve_img)\n",
    "# display(PR_curve_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydotngI9eh3B"
   },
   "source": [
    "As we have obtained the best results for yolov8s, we are going to try to improve it with 20 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxXSbb0weVwu"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data = path+ 'archive/config_image_dividing_only_airplanes.yaml', epochs = 20,  imgsz=512, save = True, val = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnVYWr1deYFe"
   },
   "outputs": [],
   "source": [
    "f1_curve_img = Image.open('/content/runs/detect/train6/F1_curve.png')\n",
    "PR_curve_img = Image.open('/content/runs/detect/train6/PR_curve.png')\n",
    "\n",
    "os.makedirs(path+'Results/image_dividing_only_airplanes', exist_ok=True)\n",
    "\n",
    "f1_curve_img.save(path+'Results/image_dividing_only_airplanes/yolov8s_F1_curve_20_epochs.png')\n",
    "PR_curve_img.save(path+'Results/image_dividing_only_airplanes/yolov8s_PR_curve_20_epochs.png')\n",
    "\n",
    "# display(f1_curve_img)\n",
    "# display(PR_curve_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h43SvPhqEhYU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
